{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZcVEBhb8+h+/ZEQfUO4XS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"16tOy2z0miZl"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","import numpy as np\n","\n","# Load BERT model once when module is imported\n","MODEL_NAME = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n","\n","def classify_sentiment(text):\n","    \"\"\"\n","    Classify sentiment using pretrained BERT model.\n","    Returns: 'negative', 'neutral', 'positive'\n","    \"\"\"\n","    if not isinstance(text, str) or text.strip() == \"\":\n","        return 'neutral'\n","\n","    inputs = tokenizer.encode(text, return_tensors='pt', truncation=True, padding=True)\n","    with torch.no_grad():\n","        outputs = model(inputs)\n","    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n","    rating = torch.argmax(probs).item() + 1  # model returns 0-4, so +1\n","\n","    # Map star rating to sentiment\n","    if rating in [1, 2]:\n","        return 'negative'\n","    elif rating == 3:\n","        return 'neutral'\n","    else:  # 4, 5\n","        return 'positive'\n"]}]}